<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Visual AI Agent</title>

<!-- Jekyll CVless Dark theme CSS -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/cckanishka/cvless-dark/cvless-dark.css">

<!-- MediaPipe -->
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/face_detection.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>

<!-- Particles.js -->
<script src="https://cdn.jsdelivr.net/npm/particles.js"></script>

<style>
/* Container adjustments for CVless dark theme */
.container { display:flex; justify-content:center; align-items:flex-start; gap:40px; margin-top:30px; flex-wrap:wrap; }
#cameraBox { display:flex; flex-direction:column; align-items:center; }
#cameraWrapper { position:relative; width:640px; height:480px; }
#webcam { width:640px; height:480px; border:2px solid #fff; }
canvas { position:absolute; top:0; left:0; width:640px; height:480px; border:2px solid lime; }
iframe { width:600px; height:480px; border:2px solid #ccc; background:#fff; }
button { padding:10px 20px; font-size:16px; margin-top:20px; cursor:pointer; color:#000; }
#explanation { font-size:18px; margin-top:15px; color:#ff0; }
</style>
</head>
<body class="dark">

<div id="particles-js"></div>

<section class="section">
  <div class="container">
    <div>
      <h1 class="title">Visual AI Agent Demo - Step-by-Step</h1>
      <p id="explanation">Waiting for face detection...</p>
    </div>
  </div>
</section>

<div class="container">
  <div id="cameraBox">
    <div id="cameraWrapper">
      <video id="webcam" autoplay playsinline></video>
      <canvas id="overlay" width="640" height="480"></canvas>
    </div>
    <button id="restartButton" class="button is-primary">Restart Camera</button>
  </div>
  <iframe id="resultsFrame" src="about:blank" sandbox="allow-scripts allow-same-origin"></iframe>
</div>

<script>
// Particles.js
particlesJS("particles-js", {
  particles: { number:{value:80}, color:{value:"#fff"}, shape:{type:"circle"}, opacity:{value:0.5}, size:{value:3}, line_linked:{enable:true,distance:150,color:"#fff",opacity:0.4,width:1}, move:{enable:true,speed:2}},
  interactivity:{ events:{ onhover:{ enable:true, mode:"repulse"}}}
});

const video=document.getElementById('webcam');
const canvas=document.getElementById('overlay');
const ctx=canvas.getContext('2d');
const iframe=document.getElementById('resultsFrame');
const restartBtn=document.getElementById('restartButton');
const explanation=document.getElementById('explanation');

let camera=null;
let detectedOnce=false;
let pausedFrame=null;

const dsTerms=["Data science","Machine learning","Artificial intelligence","Deep learning",
"Neural networks","Big data","Statistics","Predictive analytics",
"Natural language processing","Computer vision","Reinforcement learning",
"Supervised learning","Unsupervised learning","Clustering","Regression analysis"];

function getRandomTerm(){ return dsTerms[Math.floor(Math.random()*dsTerms.length)]; }

// MediaPipe Face Detection
const faceDetection=new FaceDetection({ locateFile:(file)=>`https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/${file}`});
faceDetection.setOptions({ model:'short', minDetectionConfidence:0.5 });

faceDetection.onResults(results=>{
  ctx.clearRect(0,0,canvas.width,canvas.height);
  ctx.drawImage(video,0,0,canvas.width,canvas.height);

  results.detections.forEach(d=>{
    const box=d.boundingBox;
    ctx.strokeStyle='lime';
    ctx.lineWidth=3;
    ctx.strokeRect(box.xCenter-box.width/2, box.yCenter-box.height/2, box.width, box.height);
  });

  if(results.detections.length>0 && !detectedOnce){
    detectedOnce=true;
    pausedFrame=ctx.getImageData(0,0,canvas.width,canvas.height);
    stopCamera();
    runDemoSteps();
  } else if(pausedFrame){
    ctx.putImageData(pausedFrame,0,0);
  }
});

function startCamera(){
  detectedOnce=false;
  pausedFrame=null;
  explanation.textContent="Waiting for face detection...";
  camera=new Camera(video,{onFrame:async()=>{await faceDetection.send({image:video});}, width:640,height:480});
  camera.start();
}

function stopCamera(){ if(camera){camera.stop();camera=null;} }

// Step-by-step demo with 5-second gaps, final step opens first Wikipedia entry
async function runDemoSteps(){
  const term=getRandomTerm();

  explanation.textContent=`Step 1: Face detected. Pausing camera...`;
  await new Promise(r=>setTimeout(r,5000));

  explanation.textContent=`Step 2: Preparing Bing search for "${term}"...`;
  await new Promise(r=>setTimeout(r,5000));

  explanation.textContent=`Step 3: Performing Bing search...`;
  iframe.src=`https://www.bing.com/search?q=${encodeURIComponent(term)}+site:en.wikipedia.org`;
  await new Promise(r=>setTimeout(r,5000));

  explanation.textContent=`Step 4: Opening first Wikipedia entry for "${term}"...`;
  const wikiUrl=`https://en.wikipedia.org/wiki/${encodeURIComponent(term.replace(/ /g,'_'))}`;
  iframe.src=wikiUrl;
  await new Promise(r=>setTimeout(r,5000));

  explanation.textContent=`Step 5: Demo complete! You can browse the Wikipedia page in the iframe.`;
}

restartBtn.addEventListener('click', startCamera);
startCamera();
</script>
</body>
</html>
