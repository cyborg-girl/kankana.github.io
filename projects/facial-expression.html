<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Face Expression Recognition â€” AI Portfolio</title>
<meta name="viewport" content="width=device-width, initial-scale=1">

<!-- CVless theme -->
<link rel="stylesheet" href="/assets/css/main.css">

<style>
:root{
  --bg:#0d0d0d; --card:rgba(29,53,87,0.85); --accent:#4cc9f0; --muted:#bfc9d9;
}
body {
  margin:0; padding:0; background:var(--bg); color:#fff; font-family:'Inter',sans-serif;
  overflow-x:hidden;
}
#particles-js {
  position:fixed; width:100%; height:100%; top:0; left:0; z-index:-1;
}
.wrap {
  min-height:100vh; display:flex; align-items:center; justify-content:center; padding:40px 20px; text-align:center;
}
.card {
  max-width:900px; width:100%; background:var(--card); border-radius:16px; padding:30px;
  box-shadow:0 12px 40px rgba(0,0,0,0.6);
  display:grid; grid-template-columns: 420px 1fr; gap:20px; align-items:start;
}
.left, .right { display:flex; flex-direction:column; align-items:center; gap:15px; }
.preview { width:360px; height:360px; border-radius:12px; background:#111;
display:flex; align-items:center; justify-content:center; overflow:hidden; box-shadow: inset 0 0 40px rgba(0,0,0,0.6);}
.preview video, .preview canvas { width:100%; height:100%; object-fit:cover; display:block; }
.status { font-size:0.9rem; color:var(--muted); }
.results { background:rgba(0,0,0,0.12); padding:12px; border-radius:10px; width:100%; max-width:420px; text-align:left; }
.result-item { display:flex; justify-content:space-between; padding:6px 8px; border-bottom:1px dashed rgba(255,255,255,0.06);}
.result-item:last-child{border-bottom:none;}
.confidence { font-weight:700; color:#dff7ff; }

h1 { margin:0; color:var(--accent); font-size:1.6rem; animation: fadeInDown 1s ease-out;}
p.lead { margin:0; color:var(--muted); animation: fadeIn 1.2s ease-out; }
.btn { background:linear-gradient(135deg,var(--accent),#4895ef); color:#0b1020; border:none; padding:10px 16px; border-radius:10px; font-weight:700; cursor:pointer; transition: transform 0.2s; animation: fadeInUp 1.4s ease-out;}
.btn:hover{transform:scale(1.05);}
.btn.ghost { background:transparent; color:var(--accent); border:1px solid rgba(255,255,255,0.06);}
@keyframes fadeInDown{from{opacity:0; transform:translateY(-20px);} to{opacity:1; transform:translateY(0);}}
@keyframes fadeInUp{from{opacity:0; transform:translateY(20px);} to{opacity:1; transform:translateY(0);}}
@keyframes fadeIn{from{opacity:0;} to{opacity:1;}}
@media(max-width:980px){.card{grid-template-columns:1fr;} .preview{width:100%; height:320px;}}
</style>
</head>
<body>
<div id="particles-js"></div>

<div class="wrap">
  <div class="card">
    <div class="left">
      <div class="preview" id="preview">
        <video id="video" autoplay muted playsinline></video>
      </div>
      <div class="status" id="status">Loading models...</div>
    </div>

    <div class="right">
      <h1>ðŸ˜ƒ Face Expression Recognition</h1>
      <p class="lead">Live webcam demo using TensorFlow.js & face-api.js. Recognizes expressions in real-time!</p>
      <div class="results" id="results"><div class="small">Predictions will appear here</div></div>
    </div>
  </div>
</div>

<!-- Particles.js -->
<script src="https://cdn.jsdelivr.net/npm/particles.js@2.0.0/particles.min.js"></script>
<script>
particlesJS("particles-js",{
  particles:{number:{value:70},size:{value:3},move:{speed:1},line_linked:{enable:true,distance:140,color:"#4cc9f0"},color:{value:"#4cc9f0"}},
  interactivity:{events:{onhover:{enable:true,mode:"repulse"}}}
});
</script>

<!-- face-api.js -->
<script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
<script>
async function init() {
  const statusEl = document.getElementById('status');
  const resultsEl = document.getElementById('results');
  const video = document.getElementById('video');

  try {
    await faceapi.nets.tinyFaceDetector.loadFromUri('/home/models');
    await faceapi.nets.faceExpressionNet.loadFromUri('/home/models');
    statusEl.textContent = 'Models loaded âœ…';
  } catch(err){
    console.error('Model load error', err);
    statusEl.textContent = 'Failed to load models â€” check console';
    return;
  }

  try {
    const stream = await navigator.mediaDevices.getUserMedia({ video: true });
    video.srcObject = stream;
  } catch(err) {
    console.error('Camera error', err);
    statusEl.textContent = 'Failed to access webcam';
    return;
  }

  video.addEventListener('play', () => {
    const canvas = faceapi.createCanvasFromMedia(video);
    document.getElementById('preview').append(canvas);
    const displaySize = { width: video.width || 360, height: video.height || 360 };
    faceapi.matchDimensions(canvas, displaySize);

    setInterval(async () => {
      const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceExpressions();
      const resized = faceapi.resizeResults(detections, displaySize);
      canvas.getContext('2d').clearRect(0,0,canvas.width,canvas.height);
      faceapi.draw.drawDetections(canvas, resized);
      faceapi.draw.drawFaceExpressions(canvas, resized);

      resultsEl.innerHTML = '';
      resized.forEach(det => {
        Object.entries(det.expressions).forEach(([expr, prob]) => {
          const div = document.createElement('div');
          div.className = 'result-item';
          div.innerHTML = `<span>${expr}</span><span class="confidence">${(prob*100).toFixed(1)}%</span>`;
          resultsEl.appendChild(div);
        });
      });
    }, 200);
  });
}

init();
</script>
</body>
</html>
