<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Visual AI Agent Demo</title>

<!-- MediaPipe -->
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/face_detection.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>

<!-- Particles.js -->
<script src="https://cdn.jsdelivr.net/npm/particles.js"></script>

<style>
  body {
    font-family: sans-serif;
    margin: 0;
    background: #121212;
    color: #fff;
    text-align: center;
    overflow-x: hidden;
  }
  #particles-js {
    position: fixed;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    z-index: -1;
  }
  .container {
    display: flex;
    justify-content: center;
    align-items: flex-start;
    gap: 40px; /* space between camera and iframe */
    margin-top: 30px;
    flex-wrap: wrap;
  }
  #cameraBox {
    display: flex;
    flex-direction: column;
    align-items: center;
  }
  #webcam, #overlay {
    position: absolute;
    top: 0;
    left: 0;
  }
  #cameraWrapper {
    position: relative;
    width: 640px;
    height: 480px;
  }
  #webcam { opacity: 0; } /* hide live video, only canvas shown */
  canvas { border: 2px solid #fff; }
  iframe { 
    width: 600px; 
    height: 480px; 
    border: 2px solid #ccc; 
    background: #fff; 
  }
  button { padding: 10px 20px; font-size: 16px; margin-top: 20px; cursor: pointer; color: #000; }
</style>
</head>
<body>

<div id="particles-js"></div>

<h1>Visual AI Agent Demo</h1>
<div class="container">
  <div id="cameraBox">
    <div id="cameraWrapper">
      <video id="webcam" autoplay playsinline width="640" height="480"></video>
      <canvas id="overlay" width="640" height="480"></canvas>
    </div>
    <button id="restartButton">Restart Camera</button>
  </div>
  <iframe id="wikiFrame" src="about:blank" sandbox="allow-scripts allow-same-origin"></iframe>
</div>

<script>
// Particles.js
particlesJS("particles-js", {
  particles: {
    number: { value: 80 },
    color: { value: "#ffffff" },
    shape: { type: "circle" },
    opacity: { value: 0.5 },
    size: { value: 3 },
    line_linked: { enable: true, distance: 150, color: "#ffffff", opacity: 0.4, width: 1 },
    move: { enable: true, speed: 2 }
  },
  interactivity: { events: { onhover: { enable: true, mode: "repulse" } } }
});

const video = document.getElementById('webcam');
const canvas = document.getElementById('overlay');
const ctx = canvas.getContext('2d');
const iframe = document.getElementById('wikiFrame');
const restartBtn = document.getElementById('restartButton');

let camera = null;
let detectedOnce = false;
let pausedFrame = null;

// Data science terms
const dsTerms = [
  "Data science","Machine learning","Artificial intelligence","Deep learning",
  "Neural networks","Big data","Statistics","Predictive analytics",
  "Natural language processing","Computer vision","Reinforcement learning",
  "Supervised learning","Unsupervised learning","Clustering","Regression analysis"
];

function getRandomTerm() {
    return dsTerms[Math.floor(Math.random() * dsTerms.length)];
}

// MediaPipe Face Detection
const faceDetection = new FaceDetection({
    locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/${file}`
});
faceDetection.setOptions({ model: 'short', minDetectionConfidence: 0.5 });

faceDetection.onResults(results => {
    if (pausedFrame) {
        ctx.putImageData(pausedFrame, 0, 0);
        return;
    }
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    results.detections.forEach(detection => {
        const box = detection.boundingBox;
        ctx.strokeStyle = 'lime';
        ctx.lineWidth = 3;
        ctx.strokeRect(
          box.xCenter - box.width/2,
          box.yCenter - box.height/2,
          box.width,
          box.height
        );
    });

    if (results.detections.length > 0 && !detectedOnce) {
        detectedOnce = true;
        pausedFrame = ctx.getImageData(0, 0, canvas.width, canvas.height);
        stopCamera();
        triggerAction();
    }
});

function startCamera() {
    detectedOnce = false;
    pausedFrame = null;
    camera = new Camera(video, {
        onFrame: async () => { await faceDetection.send({image: video}); },
        width: 640,
        height: 480
    });
    camera.start();
}

function stopCamera() {
    if (camera) {
        camera.stop();
        camera = null;
    }
}

function triggerAction() {
    const term = getRandomTerm();
    iframe.src = `https://www.google.com/search?q=${encodeURIComponent(term)}+site:en.wikipedia.org&btnI=I`;
    console.log(`Face detected! Wikipedia article: ${term}`);
}

// Force light mode once Wikipedia loads
iframe.addEventListener("load", () => {
  try {
    const doc = iframe.contentDocument || iframe.contentWindow.document;
    if (doc) {
      const style = doc.createElement("style");
      style.innerHTML = `
        body { background: #fff !important; color: #000 !important; }
        #mw-panel, .vector-header, .vector-sticky-header { background: #f8f9fa !important; color: #000 !important; }
      `;
      doc.head.appendChild(style);
    }
  } catch (e) {
    console.log("Cross-origin restriction: cannot inject styles directly.");
  }
});

restartBtn.addEventListener('click', () => startCamera());

startCamera();
</script>
</body>
</html>
