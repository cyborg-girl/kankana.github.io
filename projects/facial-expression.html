---
layout: projects
title: Face Expression Recognition
---

<div id="particles-js"></div>

<div class="project-container fade-in-up">
  <h1>ðŸ˜Š Face Expression Recognition</h1>
  <p>See your facial expression in real-time! ðŸ˜Ž</p>

  <div class="preview" style="position:relative; width:360px; height:360px; margin:0 auto;">
    <video id="video" autoplay muted playsinline style="width:100%; height:100%; border-radius:12px;"></video>
    <canvas id="overlay" style="position:absolute; top:0; left:0; width:100%; height:100%;"></canvas>
  </div>

  <div class="status" style="margin-top:12px;">Status: <span id="status-text">Loading models...</span></div>
</div>

<!-- Theme CSS -->
<link rel="stylesheet" href="/assets/css/main.css">

<!-- Face API -->
<script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>

<script>
const statusText = document.getElementById('status-text');
const video = document.getElementById('video');
const overlay = document.getElementById('overlay');
const overlayCtx = overlay.getContext('2d');

// Load models from hosted CDN (works over HTTPS)
async function loadModels() {
  try {
    statusText.textContent = 'Loading models...';
    await faceapi.nets.tinyFaceDetector.loadFromUri('/home/models/');
    await faceapi.nets.faceExpressionNet.loadFromUri('/home/models/');
    statusText.textContent = 'Models loaded âœ…';
    startVideo();
  } catch (err) {
    console.error(err);
    statusText.textContent = 'Failed to load models â€” check console';
  }
}

// Start webcam
async function startVideo() {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
    video.srcObject = stream;
    video.onloadedmetadata = () => video.play();
    detectExpressions();
  } catch (err) {
    console.error('Webcam error:', err);
    statusText.textContent = 'Cannot access webcam. Make sure you are on HTTPS and allow camera access.';
  }
}

// Detect expressions continuously
async function detectExpressions() {
  const displaySize = { width: video.videoWidth, height: video.videoHeight };
  faceapi.matchDimensions(overlay, displaySize);

  setInterval(async () => {
    const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
                                    .withFaceExpressions();
    overlayCtx.clearRect(0, 0, overlay.width, overlay.height);

    if (detections.length > 0) {
      detections.forEach(det => {
        const box = det.detection.box;
        overlayCtx.strokeStyle = '#4cc9f0';
        overlayCtx.lineWidth = 2;
        overlayCtx.strokeRect(box.x, box.y, box.width, box.height);

        const expressions = det.expressions;
        const sorted = Object.entries(expressions).sort((a,b)=>b[1]-a[1]);
        overlayCtx.fillStyle = '#4cc9f0';
        overlayCtx.font = '16px Inter';
        overlayCtx.fillText(sorted[0][0], box.x, box.y > 20 ? box.y-5 : box.y+15);
      });
    }
  }, 200);
}

loadModels();
</script>

<!-- Particles.js -->
<script src="https://cdn.jsdelivr.net/npm/particles.js@2.0.0/particles.min.js"></script>
<script>
particlesJS("particles-js", {
  particles: {
    number: { value: 70 },
    size: { value: 3 },
    move: { speed: 1 },
    line_linked: { enable: true, distance: 140, color: "#4cc9f0" },
    color: { value: "#4cc9f0" }
  },
  interactivity: { events: { onhover: { enable: true, mode: "repulse" } } }
});
</script>

<style>
.project-container {
  max-width: 600px;
  margin: 80px auto;
  padding: 30px;
  text-align: center;
  background: rgba(22,27,34,0.95);
  border-radius: 16px;
  box-shadow: 0 8px 30px rgba(0,0,0,0.6);
  backdrop-filter: blur(10px);
}
h1 { color:#4cc9f0; }
.status { color:#ccc; font-size:0.95rem; }
.fade-in-up { animation: fadeInUp 1s ease-out; }
@keyframes fadeInUp { from { opacity:0; transform:translateY(20px); } to { opacity:1; transform:translateY(0); } }
</style>
